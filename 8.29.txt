HTTP1.0  HTTP1.1  和 HTTP2.0的区别
影响HTTP网络请求的因素有两个：带宽和延迟

HTTP1.0和HTTP1.1：
1、缓存处理：在HTTP1.0中主要使用header里的If-Modified-Since，Expires作为缓存判断的标准，HTTP1.1则引入了更多缓存控制策略；
2、带宽优化及网络使用：HTTP1.0中，存在带宽浪费的现象，例如客户端只是需要对象的一部分，而服务器却将整个对象都传了过去，并且不支持断点续传功能，
HTTP1.1则在请求头引入了range头域，它允许之请求资源的某个部分，返回码为206，这样方便了开发者的选择以便充分利用带宽和连接；
3、Host头处理：在HTTP1.0中认为每台服务器都绑定一个唯一的主机IP，因此请求的URL中并没有携带主机名（hostname）但随着虚拟主机的发展，在一台物理机上存在多个虚拟主机，他们共享同一个IP地址。HTTP1.1的请求信息和响应信息都支持host头域，且请求信息若无host头域会报400的错误
4、长连接：HTTP1.1支持长连接和请求流水线，在一个HTTP请求中可以完成多次的HTTP请求和响应。在http1.1中默认开启Connection：keep-alive，一定程度上弥补了Http1.0每次请求都要创建连接的缺点。

SPDY：HTTP1.x的优化
1、降低延迟：针对HTTP高延迟的问题，SPDY优雅地采用多路复用（multiplexing）多路复用通过多个请求stream共享一个tcp连接的方式，解决了HOL blocking的问题，减低了延迟的同时提高了带宽的利用率。
2、请求优先级：多路复用带来一个新的问题是，在连接共享的基础之上有可能会导致关键请求被阻塞，SPDY允许每个request设置优先级，这样重要的请求就会优先得到响应
3、header压缩：Http1.1很多时候header都是重复多余的。选择合适的压缩算法可以减小包的大小和数量。
4、服务端推送：采用SPDY网页，若网页有一个style.css的请求，在客户端收到数据的同时，服务端会将style.js推送给客户端，当客户端再次尝试获取style.js时就可以直接从缓存中获取到，不用再发请求了

HTTP2.0：进化的SPDY
HTTP2.0支持HTTP明文传输
SPDY强制使用HTTPS
头部压缩算法不一样

HTTP2.0的新特性：
1、新的二进制格式：HTTP1.x是基于文本的解析，而HTTP2.0采用二进制格式，实现方便；
2、多路复用：即共享连接，即每一个request都是是用作连接共享机制的。一个request对应一个id，这样一个连接上可以用多个request，每个连接的request可以随机的混杂在一起，接收方可以根据request的id将request再归属到各自不同的服务端请求上面；
3、header压缩
4、服务端推送

多路复用vs长连接：
http1.0：一次请求一次连接，用完关闭；每个请求都要建立一个连接；
HTTP1.1：PipeLing解决方式。若干请求排队串行化单线程处理，后面的请求等待前面的请求返回才能获得执行机会，一旦有某请求超时等，后续请求只能被阻塞，毫无办法，也就是人们常说的线头阻塞；
HTTP2.0：多路复用，多个请求可同时再一个连接上并行执行，某个请求任务好事严重，不会影响其他连接的正常执行；


HTTP 性能优化的关键并不在于高带宽，而是低延迟。TCP 连接会随着时间进行自我「调谐」，起初会限制连接的最大速度，如果数据成功传输，会随着时间的推移提高传输的速度。这种调谐则被称为 TCP 慢启动。由于这种原因，让原本就具有突发性和短时性的 HTTP 连接变的十分低效。
HTTP/2 通过让所有数据流共用同一个连接，可以更有效地使用 TCP 连接，让高带宽也能真正的服务于 HTTP 的性能提升。






Redis：
redis数据类型：String，Hash，List，Set，ZSET；
redis发布订阅：subscribe ，publish
redis事务：单个redis命令的执行是原子性的，但redis没有再事务上增加任何维持原子性的机制，所以redis事务的执行并不是原子性的。
事务可以理解为一个打包的批量执行脚本，但批量命令并非原子化的操作，中间某条指令的失败不会导致前面已做指令的回滚，也不会造成后续指令不做。

redis缓存击穿、缓存雪崩、缓存穿透：
缓存穿透：
处理查询，先从缓存中读取，若有则直接返回，若无则查DB，并将val添加到缓存并设置过期时间。
查询一个一定不存在的key，则每次都会去查数据库，而数据库查询为空又不进行缓存，那么可以通过攻击压垮数据库；
解决方法：缓存空值，即查询到数据库值为空，则缓存一个空值，但过期时间较小；
缓存雪崩：
指某一段时间内，缓存集中失效；
或者更主要的是：缓存服务器某个节点宕机或者断网。
解决方法：分散缓存过期时间，加入随机因子，热门字段缓存时间长一些；冷门字段缓存短一些；
缓存击穿：
指一个key非常热点，在不停扛着大并发，大并发集中对一个点进行访问，当这个key在失效的瞬间，持续的大并发就穿透缓存，直接请求数据库，就像在屏障中凿了一个洞；
解决方案：设置热点字段永不过期；

rdb和aof：
aof文件比rdb更新频率高，优先使用aof还原数据；
aof比rdb更安全但也更大；
rdb性能比aof好；
如果两个都配了优先使用aof；

