网关：zuul
有多个微服务，他们有可能放在不同的IP地址上，有可能是不同的端口
为了访问他们，就需要记录这些地址和端口，而地址和端口都有可能会变化，这就增加了访问者的负担，所以这个时候，就可以使用网关来解决问题

API网关Spring Cloud gateway 和负载均衡框架ribbon
通常如果有一个服务，会部署到多台服务器上，这些微服务如果都暴露给客户，是非常难以管理的，我们系统需要有一个唯一的出口，API网关是一个服务，是系统的唯一出口
API网关封装了系统内部的微服务，为客户端提供一个定制的API 客户端只需要调用网关的接口，就可以调用到实际的微服务，实际的服务对客户是不可见，并且容易扩展服务
API网关可以结合ribbon完成负载均衡的功能，可以自动检查微服务的状况，及时剔除或者加入某个微服务到可用服务列表。此外网关可以完成权限检查、限流、统计等功能。下面我们将一一完成上面的功能

5个基本组件：
Eureka：作用：实现服务治理（服务i注册与发现）
简介：SpringCloudEureka是SpringCloudNetflix项目下的服务治理模块
由两个组件组成：Eureka服务端和Eureka客户端
Eureka服务端用作服务注册中心。支持集群部署
Eureka客户端是一个java客户端，用来处理服务注册与发现
在应用启动时，Eureka客户端向服务端注册自己的服务信息，同时将服务端的服务信息缓存到本地，客户端会和服务端周期性的进行心跳交互，以更新服务租约和服务信息

Ribbon：主要提供客户端的软件负载均衡算法
基于HTTP和TCP的客户端负载均衡工具，它基于NetflixRibbon实现。通过SpringCloud的封装，可以让我们轻松地将面向服务地Rest模板请求自动转换成客户端负载均衡的服务调用


Hystrix：断路器
保护系统，控制故障范围
为了保证其高可用，单个服务通常会集群部署，由于网络原因或者自身的原因，服务并不能保证100%可用，如果单个服务出现问题，调用这个服务就会出现线程阻塞，此时若有大量的请求涌入，Servlet容器的线程资源会被消耗完毕，导致服务瘫痪。服务与
服务之间的依赖性，故障会传播，会对整个微服务系统造成灾难性的严重后果，这就是服务故障的雪崩效应


Zuul：网关（Gateway）
在微服务架构中，后端服务往往不直接开放给调用端，而是通过一个API网关，根据请求的url，路由到相应的服务。当添加API网关后，在第三方调用端和服务提供方之间就创建了一面墙，这面墙直接与调用方通信进行权限控制，后将请求均衡分发到后台服务端

SpringCloud和dubbo：
Dubbo：基于RPC远程 过程调用
cloud：基于http rest api
最大的区别：SpringCloud 抛弃了Dubbo的RPC通信方式，采用了HTTP的REST方式
严格来说，这两种方式各有优劣，虽然从一定程度上，后者牺牲了服务调用的性能，但也避免了上面的原生RPC带来的问题
而且REST相比RPC更为灵活，服务提供方和调用方只依靠一纸契约，不存在代码级别的强依赖

Springboot和Springcloud：
Springboot是一个快速整合第三方框架 关注的是 微观  具体关注快速开发单个个体的服务
springcloud关注的是宏观，具体关注全局的微服务协调治理框架，将springboot开发的一个个单体服务整合并管理起来
它为各个服务之间提供配置管理 服务发现 断路器路由 微代理 全局锁 分布式会话等集成服务

hystrix断路器
Hystrix是一个用于处理分布式系统的延迟和容错的开源库，在分布式系统里，许多依赖不可避免的会调用失败（超时、异常）
Hystrix能够保证在一个依赖出现问题的情况下，不会导致整体服务失败，避免级联故障
断路器本身是一种开关装置，当某个服务单元发生故障之后，通过断路器的故障监控（类似熔断保险丝），向调用方返回一个符合预期的、可处理的备选响应（fallback），而不是长时间的等待或者抛出调用方无法处理的异常，这样
就保证了服务调用方线程不会被长时间、不必要地占用，从而避免了故障在分布式系统中地蔓延，乃至雪崩

服务熔断
熔断机制是应对雪崩效应地一种微服务链路保护机制，当扇区链路的某个微服务不可用或者响应时间太长时，会进行服务的降级，进而熔断该节点微服务的调用，快速返回“错误”的响应
当检测到该节点微服务调用响应正常后恢复调用链路。在SpringCloud框架里熔断机制通过Hystrix实现。Hystrix会监控微服务间调用的状况，当失败的调用到一定阈值，缺省5秒内20次失败，就会启动熔断机制，熔断机制的注解是@HystrixCommand
服务熔断：指某些原因使得服务出现了过载现象，为防止造成整个系统故障，从而采用的一种保护措施，所以很多地方把熔断亦称为过载保护

什么是服务降级，微服务的优缺点
服务降级：整体资源快不够了，将某些服务先关掉，待渡过难关，再开启回来

服务熔断和服务降级：
目标一致 都是从可用性和可靠性出发
用户体验类似 最终都让用户体检到的是某个功能暂时不可用

不同点：触发原因不用： 服务熔断一般是某个服务（下游）故障引起的，而服务降级一般是从整体符合考虑
通过第三方客户端的库来为访问依赖服务时的潜在故障提供保护和控制；

设计目的：
防止在复杂分布式系统中出现级联故障；

快速失败和迅速恢复；

在允许的情况下，提供退路对服务进行优雅降级；

提供近实时的监控、报警和操作控制；

erreka和zookeeper的区别：
CAP概念：CAP C:强一致性（Consistency） A：可用性（Availability） P：分区容错性（Partition Tolerance）
一个分布式系统不可能同时满足C、A、P 由于分区容错性P是在分布式系统中必须保证的，因此我们只能在A和C之间进行权衡
Consistence：所有节点访问同一份最新的数据副本
Availability：每次请求都能获取到非错的响应――但是不保证获取的数据是最新的数据
分区容错性：分布式系统在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务

一致性“all nodes see the same data at the same time”，即更新操作成功并返回客户端完成后，所有节点在同一时间的数据完全一致，所以，一致性，说的就是数据一致性
对应一致性，可以分为从客户端和服务端两个不同的视角，从客户端来看，一致性主要指多并发访问时更新过的数据如何获取的问题，从服务端来看，则是更新如何复制到整个系统，以保证数据最终一致。

可用性  ”Read and write always succeed“ 即服务一直可用，而且是正常响应时间
对于一个可用性的分布式系统，每一个非故障的节点必须对每一个请求作出响应，所以，一般我们在衡量一个系统的可用性的时候，都是通过停机时间来计算的

分区容错性”the system continues to operate despite arbitrary message loss or failure of part of the system“
即分布式系统在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务
简单说，就是在网络中断，消息丢失的情况下，系统如果还能正常工作，就是有比较好的分区容错性



CAP的权衡和选择
CAP无法同时满足，也并不是三选二
首先，P分区容错性是必须要满足的，如果舍弃分区容错，也就失去了分布式系统的意义了

CP
选择一致性放弃可用性，保证数据的正确牺牲用户体验。一个保证了CP而舍弃了A的分布式系统，一旦发生网络故障或者消息丢失的情况，就要牺牲用户的体验，等待所有数据全部一致了之后再让用户访问系统
设计成CP的系统其实也不少，其中最典型的就是很多分布式数据库，他们都是设计成CP的。在发生极端的情况下，优先保证数据的强一致性，代价就是舍弃系统的可用性。Zookeeper就是这样的
AP
要高可用并允许分区，则需放弃一致性，一旦网络问题发生，节点之间可能会失去联系。为了保证高可用，需要在用户访问时可以马上得到返回，则每个节点只能在本地数据提供服务，而这样会导致全局数据的不一致性
这种生我气强一致性而保证系统的分区容错性和可用性的场景和案例非常多，前面我们介绍可用性的时候说到过，很多系统在可用性方面会做很多事情来保证系统的全年可用性达到5个9，所以 对于很多业务系统来说，比如淘宝的购物，12306的买票，都是在可用性和一致性之间舍弃了一致性而选择可用性
比如12306，在点击购票的一瞬间是有票的，但是付款的时候可能已经没了，这就是为了保证用户体验牺牲了数据的一致性，但是还是有最终一致性的保证的，在最终购票的时候还是会保证数据一致性

对于涉及钱财这样不能一丝让步的场景，C必须保证，网络发生故障宁可停止服务，就是保证CP，舍弃A

Zookeeper和Eureka
Zookeeper保证了CP Eureka保证了AP
服务启动后向Eureka注册，Eureka Server会将注册信息向其他Eureka Server进行同步，当服务消费者要调用服务提供者，则向服务注册中心获取服务提供者的地址，然后会将服务提供者地址缓存在本地，下次再调用时，则直接从本地缓存取，完成一次调用

当服务注册中心Eureka Server检测到服务提供者因为宕机，网络原因不可用时，则再服务注册中心将服务置为DOWN状态
并把当前服务提供者状态向服务订阅者发布，订阅过的服务消费者更新本地缓存。
服务提供者在启动后，周期性向EurekaServer发送心跳，以证明当前服务是可用状态，Eureka Server在一定时间（默认90秒内）未收到客户端心跳，则认为服务宕机，注销该实例

Eureka的自我保护机制
在默认配置中，EurekaServer在默认80s内没有得到客户端的心跳，则注销该实例，但是往往因为微服务跨进程调用，网络通信往往会面临着各种问题，比如微服务正常，但是因为网络分区故障时，EurekaServer注销服务实例则会让大部分微服务不可用，这很危险，因为服务明明没有问题
为了解决这个问题，Eureka有自我保护机制，通过在Eureka Server配置参数，可启动保护机制
它的原理是，当EurekaServer节点在短时间内丢失过多的客户端时，那么这个节点将进入自我保护模式，不在注销任何微服务，当故障消除后，该节点会自动退出自我保护模式

Zookeeper保证CP
当向注册中心查询服务列表时，我们可以容忍中心返回的是几分钟以前的注册信息，但不能接收服务直接down掉。也就是说，服务注册功能对可用性的要求高于一致性，但是zk会出现这样一种情况，当master节点因为网络故障与其他节点失去联系时，剩余节点会重新进行选举。问题在于，选举的时间太长，30-120s，且整个选举期间整个zk集群都是不可用的，这就导致选举期间注册服务瘫痪。在云部署环境下，因网络问题使得zk失去master是很常见的，
虽然服务最终能恢复，但是漫长的选举时间导致的注册长期不可用是不能容忍的。

Eureka保证AP
Eureka看明白了这一点，因此在设计时优先保证了可用性，几个节点挂掉不会影响正常节点的工作，剩余的节点依然可以提供注册和查询服务。而Eureka的客户端向某个Eureka注册时如果发现连接失败，则会自动切换至其他节点，只要有一台Eureka还在，纠正保证注册服务可用，只不过查到的信息可能不是最新的
除此之外，Eureka还有一种自我保护机制，如果在15分钟内超过85%的节点都没有正常的心跳，那么Eureka就认为客户端与注册中心出现了网络故障，进入自我保护机制

因此，Eureka可以很好的应对因网络故障导致部分节点失去联系的情况，而不会像zk那样使整个注册服务瘫痪
